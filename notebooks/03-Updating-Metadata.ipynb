{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "from pyiceberg.catalog.rest import RestCatalog\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# The functions we defined in the previous notebook are defined in utils.py\n",
    "from utils import get_iceberg_manifest, get_iceberg_manifest_list, get_iceberg_metadata, read_house_prices\n",
    "from s3fs import S3FileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Updating Metadata\n",
    "\n",
    "We've added data to our tables and inspected how Iceberg keeps track of the data in the metadata files\n",
    "\n",
    "Usually when Now that we've added some data, we've found out that we've made a mistake - we should have added a `_loaded_at` column to our data, so that we can differentiate downstream between the source timestamp and our loaded time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a reference to our catalog and table again\n",
    "catalog = RestCatalog(\"lakekeeper\", uri=\"http://lakekeeper:8181/catalog\", warehouse=\"lakehouse\")\n",
    "house_prices = catalog.load_table('house_prices.raw')\n",
    "fs = S3FileSystem(endpoint_url=\"http://minio:9000\", key=\"minio\", secret=\"minio1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.now(tz=dt.UTC)\n",
    "house_prices_2022 = read_house_prices(\"data/pp-2022.csv\").with_columns(pl.lit(timestamp).alias(\"_loaded_at\"))\n",
    "house_prices_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    house_prices.upsert(house_prices_2022.to_arrow())\n",
    "except ValueError as e:\n",
    "    # Print out the error message instead of crashing\n",
    "    print(e.args[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Pyiceberg is preventing us from doing something we shouldn't - Iceberg has a fixed schema, so we can't just add arbitrary columns to it. We need to update the schema to accomodate our new column.\n",
    "\n",
    "Pyiceberg gives us the ability to do this within a transaction to live up to Iceberg's ACID guarantees.\n",
    "\n",
    "The new schema is added to the Iceberg metadata in the `schemas` array. Note that each of our snapshots reference the schema at the time the data was written. That way Iceberg can keep track of the schema evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.types import TimestamptzType\n",
    "\n",
    "with house_prices.update_schema() as schema:\n",
    "    # Avoid crashing for demo purposes\n",
    "    if \"_loaded_at\" not in house_prices.schema().column_names:\n",
    "        schema.add_column(\"_loaded_at\", TimestamptzType(), doc=\"The date this row was loaded\")\n",
    "    else:\n",
    "        print(\"_loaded_at already in schema\")\n",
    "\n",
    "get_iceberg_metadata(fs, house_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "Now we have our `_loaded_at` column as part of the table schema, Iceberg is happy for us to add our data with the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices.append(house_prices_2022.to_arrow().cast(house_prices.schema().as_arrow()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "What about the data we already added? How would we modify that data? Here we start running into some limitations of a foundational library like `pyiceberg` - we can do it, but wouldn't it be much easier to write an `UPDATE` in SQL and not have to worry about the details?\n",
    "\n",
    "This is the power of Iceberg - we have the ability to switch query engines to suit our usecase - in this case, I want to use Trino to update the data back in time.\n",
    "\n",
    "Let's use the Marimo SQL editor to quickly verify how many nulls we currently have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sa.create_engine(\"trino://trino:@trino:8080/lakekeeper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = mo.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        count(*) as all_rows,\n",
    "        NULL as null_rows\n",
    "    FROM\n",
    "        house_prices.raw\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        NULL,\n",
    "        count('*') as null_rows\n",
    "    FROM\n",
    "        house_prices.raw\n",
    "    WHERE\n",
    "        _loaded_at is null\n",
    "    \"\"\",\n",
    "    engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {},
   "source": [
    "Trino has a SQLAlchemy dialect built-in to the `trino` python package, so it's straightforward to run some SQL like we're used to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    sql = f\"UPDATE house_prices.raw SET _loaded_at = from_iso8601_timestamp('{timestamp.isoformat()}') WHERE _loaded_at is null\"\n",
    "    result = conn.execute(sa.text(sql))\n",
    "    print(result.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = mo.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        count(*) as all_rows,\n",
    "        NULL as null_rows\n",
    "    FROM\n",
    "        house_prices.raw\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        NULL,\n",
    "        count('*') as null_rows\n",
    "    FROM\n",
    "        house_prices.raw\n",
    "    WHERE\n",
    "        _loaded_at is null\n",
    "    \"\"\",\n",
    "    engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {},
   "source": [
    "We should now have a new snapshot - let's have a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_iceberg_metadata(fs, house_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {},
   "source": [
    "## Deletes\n",
    "\n",
    "We have a new operation `overwrite` - Parquet is immutable, so we have to physically write out a new file and delete the old one. That is expensive, so Iceberg uses delete files to avoid having to up-front do the work of actually deleting data.\n",
    "\n",
    "In Iceberg V2, there are positional-deletes and equality-deletes. These are both represented by a new delete file, which is just a parquet file which specifies rows to mark as deleted, either by a filter like `transaction_id = '{045A1898-4ABF-9A24-E063-4804A8C048EA}'` or by position, `filea.parquet, 0`.\n",
    "\n",
    "\\\\\\ admonition | Deprecation Warning\n",
    "Positional deletes will be replaced by deletion vectors in Iceberg V3\n",
    "\\\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_iceberg_manifest_list(fs, house_prices)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
